{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import bcolz\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: True \n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('Using gpu: %s ' % use_gpu)\n",
    "\n",
    "def gpu(x,use_gpu=use_gpu):\n",
    "    if use_gpu:\n",
    "        return x.cuda()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Dataset'\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dsets = {x: dset.ImageFolder(os.path.join(data_dir, x), transform=transform)\n",
    "         for x in ['train', 'val', 'test']}\n",
    "\n",
    "train_dataset = dset.ImageFolder('./Dataset/train', transform=transform)\n",
    "val_dataset = dset.ImageFolder('./Dataset/val', transform=transform)\n",
    "test_dataset = dset.ImageFolder('./Dataset/test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples 66071, validation examples 11016, testing examples 33154\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_dataset)\n",
    "val_size = len(val_dataset)\n",
    "test_size = len(test_dataset)\n",
    "print(\"Number of training examples {}, validation examples {}, testing examples {}\".format(train_size, val_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=6)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_vgg = models.vgg16(pretrained=True)\n",
    "print(model_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "model_vgg.classifier._modules['6'] = nn.Linear(4096, 172)\n",
    "model_vgg.classifier._modules['7'] = torch.nn.LogSoftmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=172, bias=True)\n",
      "  (7): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_vgg.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = gpu(model_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preconvfeat_val(dataset):\n",
    "    ''' Calculates the outputs of model_vgg.features (i.e., before the FC layers) on the validation dataset.\n",
    "        Returns a list of the features generated for each image, and a list of their corresponding labels.'''\n",
    "    conv_features = []\n",
    "    labels_list = []\n",
    "    i = 0 # Counter for how many batches we have processed so far.\n",
    "    for data in dataset:\n",
    "        if i % 10 == 0:\n",
    "            print(\"Completed {} forwarded passes\".format(i))\n",
    "        inputs,labels = data\n",
    "        inputs = gpu(inputs)\n",
    "        labels = gpu(labels)\n",
    "        x = model_vgg.features(inputs)\n",
    "        conv_features.extend(x.data.cpu().numpy())\n",
    "        labels_list.extend(labels.data.cpu().numpy())\n",
    "        i += 1\n",
    "    conv_features = np.concatenate([[feat] for feat in conv_features])\n",
    "    return (conv_features,labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preconvfeat_train(dataset, batches_per_file=100):\n",
    "    ''' Calculates the outputs of model_vgg.features (i.e., before the FC layers) on the training dataset.\n",
    "        Returns a list of the features generated for each image, and a list of their corresponding labels.'''\n",
    "    output_conv_features = [] # Contains a list of lists features. Each sub-list will be saved in its own file.\n",
    "    conv_features = []\n",
    "    output_labels_list = []\n",
    "    labels_list = []\n",
    "    i = 0 # Counter for how many batches we have processed so far.\n",
    "    for data in dataset:\n",
    "        # Once we have made 'batches_per_file' forward passes, we concatenate the features for each of those \n",
    "        # forward passes together, and add them to output_conv_features. This is done mainly to limit the size of \n",
    "        # the number of features we're concatenating together for the large training dataset.\n",
    "        if i >= batches_per_file:\n",
    "            print(\"Completed {} forward passes\".format(batches_per_file))\n",
    "            i = 0\n",
    "            output_conv_features.append(np.concatenate([[feat] for feat in conv_features]))\n",
    "            output_labels_list.append(labels_list)\n",
    "            conv_features = []\n",
    "            labels_list = []\n",
    "        inputs,labels = data\n",
    "        inputs = gpu(inputs)\n",
    "        labels = gpu(labels)\n",
    "        x = model_vgg.features(inputs)\n",
    "        conv_features.extend(x.data.cpu().numpy())\n",
    "        labels_list.extend(labels.data.cpu().numpy())\n",
    "        i += 1\n",
    "    if len(conv_features) > 0:\n",
    "        output_conv_features.append(np.concatenate([[feat] for feat in conv_features]))\n",
    "        output_labels_list.append(labels_list)\n",
    "    return (output_conv_features, output_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "CPU times: user 7min 23s, sys: 2min 26s, total: 9min 50s\n",
      "Wall time: 10min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_train,labels_train = preconvfeat_train(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 110 forwarded passes\n",
      "Completed 120 forwarded passes\n",
      "Completed 130 forwarded passes\n",
      "Completed 140 forwarded passes\n",
      "Completed 150 forwarded passes\n",
      "Completed 160 forwarded passes\n",
      "Completed 170 forwarded passes\n",
      "CPU times: user 1min 13s, sys: 26.2 s, total: 1min 39s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_val,labels_val = preconvfeat_val(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./vgg16’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "def save_array_train(fname, arr):\n",
    "    for i, arr_list in enumerate(arr): \n",
    "        c=bcolz.carray(arr_list, rootdir=fname + \"_\" + str(i) + '.bc', mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def save_array_val(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "%mkdir ./vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array_train(os.path.join('./vgg16','feat_train'), conv_feat_train)\n",
    "save_array_train(os.path.join('./vgg16','labels_train'), labels_train)\n",
    "save_array_val(os.path.join('./vgg16','feat_val.bc'), conv_feat_val)\n",
    "save_array_val(os.path.join('./vgg16','labels_val.bc'),labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training fully connected module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat_val = load_array('./vgg16/feat_val.bc')\n",
    "labels_val = load_array('./vgg16/labels_val.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11016\n",
      "(11016, 512, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "print(len(conv_feat_val))\n",
    "print(conv_feat_val.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
