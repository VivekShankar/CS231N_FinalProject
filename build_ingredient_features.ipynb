{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import bcolz\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: True \n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('Using gpu: %s ' % use_gpu)\n",
    "\n",
    "def gpu(x,use_gpu=use_gpu):\n",
    "    if use_gpu:\n",
    "        return x.cuda()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Dataset'\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class ImageFolderWithPaths(dset.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "train_dataset = ImageFolderWithPaths('./Dataset/train', transform=transform)\n",
    "val_dataset = ImageFolderWithPaths('./Dataset/val', transform=transform)\n",
    "test_dataset = ImageFolderWithPaths('./Dataset/test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples 66071, validation examples 11016, testing examples 33154\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_dataset)\n",
    "val_size = len(val_dataset)\n",
    "test_size = len(test_dataset)\n",
    "print(\"Number of training examples {}, validation examples {}, testing examples {}\".format(train_size, val_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=6)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=6)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64]) ('./Dataset/train/54/15_42.jpg', './Dataset/train/42/6_22.jpg', './Dataset/train/101/11_39.jpg', './Dataset/train/161/9_38.jpg', './Dataset/train/62/13_52.jpg', './Dataset/train/22/7_5.jpg', './Dataset/train/55/20_29.jpg', './Dataset/train/109/4_11.jpg', './Dataset/train/15/19_26.jpg', './Dataset/train/82/8_32.jpg', './Dataset/train/53/7_6.jpg', './Dataset/train/103/1_36.jpg', './Dataset/train/148/13_11.jpg', './Dataset/train/16/21_18.jpg', './Dataset/train/105/19_20.jpg', './Dataset/train/67/15_31.jpg', './Dataset/train/71/2_22.jpg', './Dataset/train/86/1_20.jpg', './Dataset/train/97/8_0.jpg', './Dataset/train/13/13_43.jpg', './Dataset/train/106/afe37626ae96661e2658b69f23548be0.jpg', './Dataset/train/109/13_35.jpg', './Dataset/train/97/19_7.jpg', './Dataset/train/88/2_33.jpg', './Dataset/train/3/1_22.jpg', './Dataset/train/37/14_36.jpg', './Dataset/train/93/20_17.jpg', './Dataset/train/143/12_12.jpg', './Dataset/train/164/13_2.jpg', './Dataset/train/18/3_15.jpg', './Dataset/train/130/4_15.jpg', './Dataset/train/157/10_56.jpg', './Dataset/train/50/4_3.jpg', './Dataset/train/14/17_32.jpg', './Dataset/train/22/1_3.jpg', './Dataset/train/170/9_47.jpg', './Dataset/train/8/13_10.jpg', './Dataset/train/28/12_24.jpg', './Dataset/train/134/3_34.jpg', './Dataset/train/6/10_18.jpg', './Dataset/train/108/5_35.jpg', './Dataset/train/72/20_25.jpg', './Dataset/train/24/6_42.jpg', './Dataset/train/77/7_4.jpg', './Dataset/train/64/5_7.jpg', './Dataset/train/91/13_41.jpg', './Dataset/train/43/2_33.jpg', './Dataset/train/56/4_33.jpg', './Dataset/train/33/14_10.jpg', './Dataset/train/65/16_12.jpg', './Dataset/train/138/16_29.jpg', './Dataset/train/71/16_41.jpg', './Dataset/train/44/8_4.jpg', './Dataset/train/141/1_17.jpg', './Dataset/train/89/9_44.jpg', './Dataset/train/103/21_20.jpg', './Dataset/train/164/4_12.jpg', './Dataset/train/133/3_2.jpg', './Dataset/train/59/13_42.jpg', './Dataset/train/117/11_29.jpg', './Dataset/train/20/19_0.jpg', './Dataset/train/68/21_34.jpg', './Dataset/train/133/14_25.jpg', './Dataset/train/138/5_5.jpg')\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for inputs, labels, paths in train_dataloader:\n",
    "    # use the above variables freely\n",
    "    print(inputs.shape, labels.shape, paths)\n",
    "    c += 1\n",
    "    if c == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IngreLabel = open('IngreLabel.txt', 'r').read().split('\\n')  # list of str\n",
    "for i in range(len(IngreLabel)):\n",
    "    IngreLabel[i] = IngreLabel[i].split()                    # list of list, element is str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IngreLabel = open('IngreLabel.txt', 'r').read().split('\\n')[:-1]  # list of str\n",
    "path_to_ingredients = dict()\n",
    "for i in range(len(IngreLabel)):\n",
    "    path_and_ingredients = IngreLabel[i].split()\n",
    "    path, ingredients = path_and_ingredients[0], [0 if int(label) == -1 else int(label) for label in path_and_ingredients[1:]]\n",
    "    path_to_ingredients[path] = np.array(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_to_ingredients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-207a5a59bdd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_ingredients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/100/xiachufang_1.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_ingredients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/100/xiachufang_1.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_ingredients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_to_ingredients' is not defined"
     ]
    }
   ],
   "source": [
    "print(path_to_ingredients['/100/xiachufang_1.jpg'].shape)\n",
    "print(len(path_to_ingredients['/100/xiachufang_1.jpg']))\n",
    "print(len(path_to_ingredients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients(path):\n",
    "    split_path = path.split(\"/\")\n",
    "    key = '/' + '/'.join(split_path[3:])\n",
    "    ingredients = path_to_ingredients[key]\n",
    "    return ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_vgg = models.vgg16(pretrained=True)\n",
    "print(model_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = gpu(model_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preconvfeat_val(dataset):\n",
    "    ''' Calculates the outputs of model_vgg.features (i.e., before the FC layers) on the validation dataset.\n",
    "        Returns a list of the features generated for each image, and a list of their corresponding labels.'''\n",
    "    conv_features = []\n",
    "    food_labels_list = []\n",
    "    ingredient_labels_list = []\n",
    "    i = 0 # Counter for how many batches we have processed so far.\n",
    "    for data in dataset:\n",
    "        if i % 10 == 0:\n",
    "            print(\"Completed {} forwarded passes\".format(i))\n",
    "        inputs, food_labels, paths = data\n",
    "        ingredient_labels = []\n",
    "        for path in paths:\n",
    "            ingredient_labels.append(get_ingredients(path))\n",
    "        inputs = gpu(inputs)\n",
    "        food_labels = gpu(food_labels)\n",
    "        x = model_vgg.features(inputs)\n",
    "        conv_features.extend(x.data.cpu().numpy())\n",
    "        food_labels_list.extend(food_labels.data.cpu().numpy())\n",
    "        ingredient_labels_list.extend(ingredient_labels)\n",
    "        i += 1\n",
    "    conv_features = np.concatenate([[feat] for feat in conv_features])\n",
    "    return (conv_features, food_labels_list, ingredient_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preconvfeat_train(dataset, batches_per_file=100):\n",
    "    ''' Calculates the outputs of model_vgg.features (i.e., before the FC layers) on the training dataset.\n",
    "        Returns a list of the features generated for each image, and a list of their corresponding labels.'''\n",
    "    output_conv_features = [] # Contains a list of lists features. Each sub-list will be saved in its own file.\n",
    "    conv_features = []\n",
    "    output_food_labels_list = []\n",
    "    food_labels_list = []\n",
    "    output_ingredient_labels_list = []\n",
    "    ingredient_labels_list = []\n",
    "    i = 0 # Counter for how many batches we have processed so far.\n",
    "    for data in dataset:\n",
    "        # Once we have made 'batches_per_file' forward passes, we concatenate the features for each of those \n",
    "        # forward passes together, and add them to output_conv_features. This is done mainly to limit the size of \n",
    "        # the number of features we're concatenating together for the large training dataset.\n",
    "        if i >= batches_per_file:\n",
    "            print(\"Completed {} forward passes\".format(batches_per_file))\n",
    "            i = 0\n",
    "            output_conv_features.append(np.concatenate([[feat] for feat in conv_features]))\n",
    "            output_food_labels_list.append(food_labels_list)\n",
    "            output_ingredient_labels_list.append(ingredient_labels_list)\n",
    "            conv_features = []\n",
    "            food_labels_list = []\n",
    "            ingredient_labels_list = []\n",
    "        inputs, food_labels, paths = data\n",
    "        ingredient_labels = []\n",
    "        for path in paths:\n",
    "            ingredient_labels.append(get_ingredients(path))\n",
    "        inputs = gpu(inputs)\n",
    "        labels = gpu(food_labels)\n",
    "        x = model_vgg.features(inputs)\n",
    "        conv_features.extend(x.data.cpu().numpy())\n",
    "        food_labels_list.extend(labels.data.cpu().numpy())\n",
    "        ingredient_labels_list.extend(ingredient_labels)\n",
    "        i += 1\n",
    "    if len(conv_features) > 0:\n",
    "        output_conv_features.append(np.concatenate([[feat] for feat in conv_features]))\n",
    "        output_food_labels_list.append(food_labels_list)\n",
    "        output_ingredient_labels_list.append(ingredient_labels_list)\n",
    "    return (output_conv_features, output_food_labels_list, output_ingredient_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 forward passes\n",
      "Completed 100 forward passes\n",
      "Completed 100 forward passes\n",
      "Completed 100 forward passes\n",
      "Completed 100 forward passes\n",
      "Completed 100 forward passes\n",
      "Completed 100 forward passes\n",
      "Completed 100 forward passes\n",
      "Completed 100 forward passes\n",
      "Completed 100 forward passes\n",
      "CPU times: user 7min 42s, sys: 2min 28s, total: 10min 10s\n",
      "Wall time: 10min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_train, food_labels_train, ingredient_labels_train = preconvfeat_train(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 forwarded passes\n",
      "Completed 10 forwarded passes\n",
      "Completed 20 forwarded passes\n",
      "Completed 30 forwarded passes\n",
      "Completed 40 forwarded passes\n",
      "Completed 50 forwarded passes\n",
      "Completed 60 forwarded passes\n",
      "Completed 70 forwarded passes\n",
      "Completed 80 forwarded passes\n",
      "Completed 90 forwarded passes\n",
      "Completed 100 forwarded passes\n",
      "Completed 110 forwarded passes\n",
      "Completed 120 forwarded passes\n",
      "Completed 130 forwarded passes\n",
      "Completed 140 forwarded passes\n",
      "Completed 150 forwarded passes\n",
      "Completed 160 forwarded passes\n",
      "Completed 170 forwarded passes\n",
      "CPU times: user 1min 17s, sys: 25.6 s, total: 1min 42s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_val, food_labels_val, ingredient_labels_val = preconvfeat_val(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./ingredients/vgg16’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "def save_array_train(fname, arr):\n",
    "    for i, arr_list in enumerate(arr): \n",
    "        c=bcolz.carray(arr_list, rootdir=fname + \"_\" + str(i) + '.bc', mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def save_array_val(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "%mkdir ./ingredients/vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array_train(os.path.join('./ingredients/vgg16','feat_train'), conv_feat_train)\n",
    "save_array_train(os.path.join('./ingredients/vgg16','food_labels_train'), food_labels_train)\n",
    "save_array_train(os.path.join('./ingredients/vgg16','ingredient_labels_train'), ingredient_labels_train)\n",
    "\n",
    "# save_array_val(os.path.join('./ingredients/vgg16','feat_val.bc'), conv_feat_val)\n",
    "# save_array_val(os.path.join('./ingredients/vgg16','food_labels_val.bc'), food_labels_val)\n",
    "# save_array_val(os.path.join('./ingredients/vgg16','ingredient_labels_val.bc'), ingredient_labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training fully connected module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat_val = load_array('./vgg16/feat_val.bc')\n",
    "labels_val = load_array('./vgg16/labels_val.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11016\n",
      "(11016, 512, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "print(len(conv_feat_val))\n",
    "print(conv_feat_val.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
