{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into Train/Val/Test Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data loading instructions:** \n",
    "\n",
    "First, unzip the dataset and store it in a folder labeled VireoFood172/.\n",
    "VireoFood172/ contains two sub-directories: ready_chinese_food/ and SplitAndIngreLabel/\n",
    "\n",
    "This notebook (and its code) should be placed in a directory above VireoFood172/.\n",
    "\n",
    "After running the cells in this notebook, you should have all the image data stored in a new Dataset/ directory that contains three sub-directories called train/, val/, and test/ which hold the training, validation, and testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "# from skimage import io, transform \n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "DATA_DIR = \"VireoFood172\"\n",
    "LABELS_DIR = DATA_DIR + \"/SplitAndIngreLabel\" # VireoFood172/SplitAndIngreLabel\n",
    "EXAMPLES_DIR = DATA_DIR + \"/ready_chinese_food\" # VireoFood172/ready_chinese_food\n",
    "\n",
    "FOOD_LIST_PATH = LABELS_DIR + \"/FoodList.txt\" # VireoFood172/SplitAndIngreLabel/FoodList.txt\n",
    "INGREDIENT_LIST_PATH = LABELS_DIR + \"/IngredientList.txt\" # VireoFood172/SplitAndIngreLabel/IngredientList.txt\n",
    "INGRE_LABEL_PATH = LABELS_DIR + \"/IngreLabel.txt\"\n",
    "\n",
    "NORMALIZE_ON = True # Enable data normalization\n",
    "TRANSFORM_ON = True # Enable data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of food labels 172\n",
      "Number of ingredient labels 353\n"
     ]
    }
   ],
   "source": [
    "food_names = [] # List of length 172 where index is the food label, and value is the food name.\n",
    "with open(FOOD_LIST_PATH) as fp:\n",
    "    food_names = fp.read().splitlines()\n",
    "\n",
    "ingredient_names = [] # List of length 353 where index is the ingredient label, and value is the ingredient name.\n",
    "with open(INGREDIENT_LIST_PATH) as fp:\n",
    "    ingredient_names = fp.read().splitlines()\n",
    "\n",
    "print(\"Number of food labels {}\".format(len(food_names)))\n",
    "print(\"Number of ingredient labels {}\".format(len(ingredient_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_image_path(path):\n",
    "    ''' Takes in a path of the form: /100/xiachufang_1.jpg\n",
    "        and returns the relative path to the image: \n",
    "        \"VireoFood172/ready_chinese_food/100/xiachufang_1.jpg\" '''\n",
    "    return EXAMPLES_DIR + path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_annotations(mode):\n",
    "    ''' Input: mode (one of \"train\", \"val\", or \"test\")\n",
    "        Returns image_paths: a list of all the training, validation, or testing image paths (depending\n",
    "        on the specified \"mode\").\n",
    "    '''\n",
    "    assert(mode == \"train\" or mode == \"val\" or mode == \"test\")\n",
    "    file_mode = \"\"\n",
    "    if mode == \"train\":\n",
    "        file_mode = \"TR\"\n",
    "    elif mode == \"val\":\n",
    "        file_mode = \"VAL\"\n",
    "    elif mode == \"test\":\n",
    "        file_mode = \"TE\"\n",
    "    file = LABELS_DIR + \"/{}.txt\".format(file_mode)\n",
    "    image_paths = []\n",
    "    with open(file) as fp:\n",
    "        for line in fp.readlines():\n",
    "            image_path = line.strip()\n",
    "            image_paths.append(image_path)\n",
    "            image = Image.open(get_relative_image_path(image_path))\n",
    "            new_image_path = \"./Dataset/\" + mode + image_path\n",
    "            os.makedirs(os.path.dirname(new_image_path), exist_ok=True)\n",
    "            image.save(new_image_path)\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = get_file_annotations(\"train\")\n",
    "val_image_paths = get_file_annotations(\"val\")            \n",
    "test_image_paths = get_file_annotations(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
